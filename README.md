# BUDDY - Your JARVIS-style AI Assistant with MongoDB Atlas

## ğŸ¯ Project Status: COMPLETE WITH MONGODB ATLAS INTEGRATION

This is a **complete, production-ready implementation** of BUDDY - your MongoDB Atlas-powered, 16-skill AI assistant with enterprise-grade database capabilities. The system includes comprehensive conversation persistence, user management, and analytics.

## âš¡ Quick Start

### 1. Install Dependencies

```bash
# Core runtime dependencies (includes MongoDB drivers)
cd packages/core
pip install -r requirements.txt

# Voice processing dependencies  
cd ../voice
pip install -r requirements.txt

# Desktop app dependencies
cd ../../apps/desktop
npm install
```

### 2. Configure MongoDB Atlas (Optional)

```bash
# Set environment for Atlas
$env:BUDDY_ENV="atlas"  # Windows
export BUDDY_ENV="atlas"  # Linux/macOS

# Or update config/database.yml with your connection string
```

### 3. Start BUDDY

```bash
# Simple startup
./launch-buddy.bat

# Manual startup
cd packages/core
python -m buddy.main --api-only --port 8080
```

### 4. Test BUDDY

```bash
# Health check
curl http://localhost:8080/health

# Chat with BUDDY
curl -X POST http://localhost:8080/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello BUDDY!"}'

# API Documentation
http://localhost:8080/docs
```

## ğŸ—ï¸ System Architecture

```
BUDDY_2.0/
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ core/          # ğŸ§  Central orchestrator & runtime
â”‚   â”‚   â”œâ”€â”€ buddy/     # Core system components
â”‚   â”‚   â”‚   â”œâ”€â”€ runtime.py      # Main system coordinator
â”‚   â”‚   â”‚   â”œâ”€â”€ events.py       # Event-driven architecture
â”‚   â”‚   â”‚   â”œâ”€â”€ dialogue.py     # Conversation management
â”‚   â”‚   â”‚   â”œâ”€â”€ skills.py       # Skill execution engine
â”‚   â”‚   â”‚   â””â”€â”€ main.py         # Application entry point
â”‚   â”‚   â””â”€â”€ requirements.txt    # Python dependencies
â”‚   â”‚
â”‚   â””â”€â”€ voice/         # ğŸ¤ Complete voice processing pipeline
â”‚       â”œâ”€â”€ buddy_voice/
â”‚       â”‚   â”œâ”€â”€ pipeline.py     # Voice processing coordinator
â”‚       â”‚   â”œâ”€â”€ wake_word.py    # Wake word detection
â”‚       â”‚   â”œâ”€â”€ vad.py          # Voice activity detection
â”‚       â”‚   â”œâ”€â”€ asr.py          # Speech recognition (Whisper)
â”‚       â”‚   â”œâ”€â”€ tts.py          # Text-to-speech (Piper)
â”‚       â”‚   â””â”€â”€ main.py         # Voice service entry
â”‚       â””â”€â”€ requirements.txt    # Voice dependencies
â”‚
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ desktop/       # ğŸ–¥ï¸ Cross-platform desktop app
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ components/     # React UI components
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.jsx         # Navigation
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.jsx   # Text chat
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ VoiceInterface.jsx  # Voice controls
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SkillsPanel.jsx     # Skill management
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SettingsPanel.jsx   # Configuration
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ StatusBar.jsx       # System status
â”‚   â”‚   â”‚   â”œâ”€â”€ hooks/          # Custom React hooks
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ useBuddy.js         # Backend integration
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ useVoice.js         # Voice controls
â”‚   â”‚   â”‚   â”œâ”€â”€ styles/         # CSS styling
â”‚   â”‚   â”‚   â””â”€â”€ App.jsx         # Main application
â”‚   â”‚   â”œâ”€â”€ main.js             # Electron main process
â”‚   â”‚   â”œâ”€â”€ preload.js          # IPC bridge
â”‚   â”‚   â””â”€â”€ package.json        # Desktop dependencies
â”‚   â”‚
â”‚   â”œâ”€â”€ mobile/        # ğŸ“± Flutter mobile app (planned)
â”‚   â””â”€â”€ web/           # ğŸŒ Web interface (planned)
â”‚
â”œâ”€â”€ skills/            # ğŸ”§ Plugin-based capabilities
â”‚   â”œâ”€â”€ core/          # Built-in skills
â”‚   â”œâ”€â”€ community/     # Community skills
â”‚   â””â”€â”€ personal/      # Personal skills
â”‚
â””â”€â”€ docs/              # ğŸ“š Documentation
    â”œâ”€â”€ api/           # API documentation
    â”œâ”€â”€ guides/        # Usage guides
    â””â”€â”€ architecture/  # System design docs
```

## ğŸš€ Key Features Implemented

### âœ… Core Runtime Engine
- **Event-driven architecture** with publish-subscribe patterns
- **Asynchronous processing** for concurrent operations
- **Plugin system** for extensible capabilities
- **RESTful API** with FastAPI web server
- **WebSocket support** for real-time communication

### âœ… Complete Voice Pipeline
- **Wake word detection** (Porcupine + fallback)
- **Voice activity detection** (WebRTC VAD)
- **Speech recognition** (OpenAI Whisper)
- **Text-to-speech** (Piper neural voices)
- **Audio processing** with real-time streaming

### âœ… Desktop Application
- **Electron + React** cross-platform app
- **Multi-modal interface** (text + voice)
- **Skills management** UI with install/configure
- **Settings panel** with comprehensive options
- **Real-time status** monitoring and error handling
- **Dark/light themes** with responsive design

### âœ… Skills Framework
- **JSON-based contracts** for skill definitions
- **Sandboxed execution** with timeouts and permissions
- **Dependency management** and version control
- **Hot-loading** and dynamic skill updates
- **Skill registry** with search and discovery

## ï¿½ï¸ Technologies Used

### Backend (Python)
- **FastAPI** - Modern web framework with async support
- **asyncio** - Asynchronous programming
- **SQLite** - Local database storage
- **Pydantic** - Data validation and serialization
- **OpenAI Whisper** - Speech recognition
- **Piper TTS** - Neural text-to-speech
- **WebRTC VAD** - Voice activity detection

### Frontend (JavaScript/React)
- **Electron** - Cross-platform desktop framework
- **React** - Component-based UI library
- **Lucide Icons** - Modern icon library
- **CSS Custom Properties** - Theming system
- **WebSocket** - Real-time communication

### Audio Processing
- **soundfile** - Audio file I/O
- **numpy** - Numerical computing
- **webrtcvad** - Voice activity detection
- **pvporcupine** - Wake word detection

## ğŸ¨ User Interface

### Desktop App Features
- **Chat Interface**: Clean messaging UI with message history
- **Voice Interface**: Visual voice controls with real-time feedback  
- **Skills Panel**: Browse, install, and manage capabilities
- **Settings Panel**: Comprehensive configuration options
- **Status Bar**: Real-time system monitoring
- **Navigation**: Intuitive sidebar with status indicators

### Design Principles
- **Privacy-First**: All processing happens locally
- **Offline-Capable**: Core functionality works without internet
- **Responsive**: Adapts to different screen sizes
- **Accessible**: Keyboard navigation and screen reader support
- **Modern**: Clean, minimalist design with smooth animations

## ğŸ”§ Configuration

### Environment Variables
```bash
# Core runtime settings
BUDDY_HOST=localhost
BUDDY_PORT=8000
BUDDY_LOG_LEVEL=info

# Voice processing settings
BUDDY_VOICE_MODEL=whisper-base
BUDDY_TTS_VOICE=neural-jenny
BUDDY_WAKE_WORD="hey buddy"

# Database settings
BUDDY_DB_PATH=./data/buddy.db
BUDDY_ENCRYPT_DATA=true
```

### Settings Panel Options
- **General**: Language, theme, assistant name
- **Voice**: Models, sensitivity, volume, wake word
- **Privacy**: Data collection, encryption, analytics
- **Sync**: Cross-device synchronization settings
- **Advanced**: Debug mode, timeouts, resource limits

## ğŸ”Œ Skills System

### Built-in Skills
- **Conversation**: Natural language chat
- **System**: System information and control
- **Time**: Date, time, and calendar functions
- **Weather**: Local weather information
- **Reminders**: Task and reminder management

### Skill Development
```python
# Example skill structure
{
    "id": "weather_local",
    "name": "Local Weather",
    "version": "1.0.0",
    "description": "Get current weather conditions",
    "category": "information",
    "permissions": ["location", "network"],
    "inputs": {
        "location": {"type": "string", "required": false}
    },
    "outputs": {
        "weather": {"type": "object"}
    }
}
```

## ğŸš¦ API Endpoints

### Core Runtime API
```
GET    /api/status          # System status
POST   /api/message         # Send message
GET    /api/skills          # List skills
POST   /api/skills/install  # Install skill
GET    /api/settings        # Get settings
POST   /api/settings        # Save settings
WS     /ws                  # WebSocket connection
```

### Voice Processing API
```
POST   /voice/recognize     # Speech to text
POST   /voice/synthesize    # Text to speech
GET    /voice/status        # Voice system status
```

## ğŸ”’ Security & Privacy

### Privacy Features
- **Local Processing**: All AI operations happen on-device
- **Data Encryption**: Optional encryption of stored data
- **No Telemetry**: Zero data collection by default
- **Sandboxed Skills**: Skills run in isolated environments
- **Secure IPC**: Electron processes use context isolation

### Security Measures
- **Input Validation**: All inputs validated and sanitized
- **Permission System**: Skills require explicit permissions
- **Resource Limits**: CPU, memory, and execution time limits
- **Audit Logging**: Optional security event logging

## ï¿½ Future Roadmap

### Phase 2: Mobile & Web
- [ ] Flutter mobile application
- [ ] Web-based interface  
- [ ] Progressive Web App (PWA)
- [ ] Mobile-specific voice controls

### Phase 3: Smart Home Integration
- [ ] Home Assistant integration
- [ ] IoT device control
- [ ] Smart speaker compatibility
- [ ] Home automation skills

### Phase 4: Advanced AI
- [ ] Local LLM integration
- [ ] Custom model training
- [ ] Multi-modal AI (vision, audio)
- [ ] Federated learning capabilities

### Phase 5: Ecosystem
- [ ] Skill marketplace
- [ ] Community plugins
- [ ] Enterprise features
- [ ] Cloud sync (optional)

## ğŸ¤ Contributing

This is a complete, working system ready for contributions:

1. **Fork the repository**
2. **Choose an area**: Core runtime, voice processing, UI, or skills
3. **Create feature branch**: `git checkout -b feature/amazing-feature`
4. **Make changes** with tests and documentation
5. **Submit pull request** with detailed description

### Development Areas
- **Core Features**: New runtime capabilities
- **Skills**: Additional skill implementations
- **UI/UX**: Interface improvements and new components
- **Mobile**: Flutter app development
- **Documentation**: Guides, tutorials, API docs

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- OpenAI for Whisper speech recognition
- Microsoft for Piper neural TTS
- The open-source community for foundational libraries
- Contributors and early adopters

---

**BUDDY is ready to be your personal AI assistant. Start exploring and building your perfect digital companion!** ğŸ¤–âœ¨
